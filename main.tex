\newif\ifpictures
\picturestrue

\newif\ifjournal
\journaltrue

\newif\ifArXiv
\ArXivfalse

\documentclass[12pt]{amsart}
\usepackage{amssymb,amsmath}
 \usepackage{amsopn}
 \usepackage{xspace}
  \usepackage{hyperref}
 \usepackage[dvips]{graphicx}
\usepackage[arrow,matrix,curve]{xy}
\usepackage {color, tikz}
\usepackage{wasysym}


\headheight=8pt
\topmargin=30pt 
\textheight=611pt     \textwidth=456pt
\oddsidemargin=6pt   \evensidemargin=6pt

\numberwithin{equation}{section}
\newtheorem{thm}{Theorem}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{remark}[thm]{Remark}


\theoremstyle{definition}

\newtheorem{definition}[thm]{Definition}
\newtheorem{example}[thm]{Example}

\numberwithin{thm}{section}


\newcounter{FNC}[page]
\def\newfootnote#1{{\addtocounter{FNC}{2}$^\fnsymbol{FNC}$%
     \let\thefootnote\relax\footnotetext{$^\fnsymbol{FNC}$#1}}}

\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\B}{\mathbb{B}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\TP}{\mathbb{TP}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\tri}{\triangle}
\newcommand{\lf}{\left}
\newcommand{\ri}{\right}
\newcommand{\ra}{\rightarrow}
\newcommand{\la}{\leftarrow} 
\newcommand{\Ra}{\Rightarrow}
\newcommand{\La}{\Leftarrow}
\newcommand{\Lera}{\Leftrightarrow}
\newcommand{\ovl}{\overline}
\newcommand{\wh}{\widehat}
\newcommand{\lan}{\langle}
\newcommand{\ran}{\rangle}

\newcommand\cA{{\ensuremath{\mathcal{A}}}\xspace}
\newcommand\cB{{\ensuremath{\mathcal{B}}}\xspace}
\newcommand\cC{{\ensuremath{\mathcal{C}}}\xspace}
\newcommand\cD{{\ensuremath{\mathcal{D}}}\xspace}
\newcommand\cE{{\ensuremath{\mathcal{E}}}\xspace}
\newcommand\cF{{\ensuremath{\mathcal{F}}}\xspace}
\newcommand\cG{{\ensuremath{\mathcal{G}}}\xspace}
\newcommand\cH{{\ensuremath{\mathcal{H}}}\xspace}
\newcommand\cI{{\ensuremath{\mathcal{I}}}\xspace}
\newcommand\cJ{{\ensuremath{\mathcal{J}}}\xspace}
\newcommand\cK{{\ensuremath{\mathcal{K}}}\xspace}
\newcommand\cL{{\ensuremath{\mathcal{L}}}\xspace}
\newcommand\cM{{\ensuremath{\mathcal{M}}}\xspace}
\newcommand\cN{{\ensuremath{\mathcal{N}}}\xspace}
\newcommand\cO{{\ensuremath{\mathcal{O}}}\xspace}
\newcommand\cP{{\ensuremath{\mathcal{P}}}\xspace}
\newcommand\cQ{{\ensuremath{\mathcal{Q}}}\xspace}
\newcommand\cR{{\ensuremath{\mathcal{R}}}\xspace}
\newcommand\cS{{\ensuremath{\mathcal{S}}}\xspace}
\newcommand\cT{{\ensuremath{\mathcal{T}}}\xspace}
\newcommand\cU{{\ensuremath{\mathcal{U}}}\xspace}
\newcommand\cV{{\ensuremath{\mathcal{V}}}\xspace}
\newcommand\cW{{\ensuremath{\mathcal{W}}}\xspace}
\newcommand\cX{{\ensuremath{\mathcal{X}}}\xspace}
\newcommand\cY{{\ensuremath{\mathcal{Y}}}\xspace}
\newcommand\cZ{{\ensuremath{\mathcal{Z}}}\xspace}

\newcommand{\eps}{\varepsilon}
\newcommand{\vphi}{\varphi}
\newcommand{\alp}{\alpha}
\newcommand{\lam}{\lambda}
\newcommand{\kro}{\delta}
\newcommand{\sig}{\sigma}
\newcommand{\Sig}{\Sigma}
\newcommand{\lap}{\Delta}
\newcommand{\Gam}{\Gamma}


\definecolor{DarkGreen}{rgb}{0,0.65,0}
\newcommand{\yixuan}[1]{{\color{orange} \sf $\clubsuit\clubsuit\clubsuit$ Yixuan: [#1]}}
\newcommand{\mareike}[1]{{\color{cyan} \sf $\clubsuit\clubsuit\clubsuit$ Mareike: [#1]}}
\newcommand{\assum}{{\color{red} \sf $(\clubsuit)$}}
\newcommand{\durch}[1]{\textcolor{red}{\sout{#1}}}


\newcommand{\struc}[1]{{\color{blue} #1}}
\newcommand{\alert}[1]{{\color{red} #1}}


\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\tconv}{tconv}
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\lin}{lin}
\DeclareMathOperator{\trop}{trop}
\DeclareMathOperator{\aff}{aff}
\DeclareMathOperator{\LP}{LP}
\DeclareMathOperator{\Arg}{Arg}
\DeclareMathOperator{\Log}{Log}
\DeclareMathOperator{\New}{New}
\DeclareMathOperator{\tdeg}{tdeg}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\re}{re}
\DeclareMathOperator{\im}{im} 
\DeclareMathOperator{\odd}{odd} 
\DeclareMathOperator{\even}{even} 
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\Circ}{Circ}

\DeclareMathOperator{\res}{res}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\RE}{Re}
\DeclareMathOperator{\IM}{Im}
\DeclareMathOperator{\w}{\wedge}
\DeclareMathOperator{\val}{val}
\DeclareMathOperator{\Val}{Val}
\DeclareMathOperator{\coA}{\text{co}\cA}
\DeclareMathOperator{\coL}{\text{co}\cL}
\DeclareMathOperator{\eq}{eq}
\DeclareMathOperator{\app}{app}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\ini}{in}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\Int}{int}
\DeclareMathOperator{\SOS}{SOS}
\DeclareMathOperator{\prep}{Prep}

\DeclareMathOperator{\verti}{Vert}
\DeclareMathOperator{\coeffs}{coeffs}


\def\endexa{\hfill$\hexagon$}

\title{Honors Project}

\author{Yixuan Zhou} \author{Mareike Dressler} %\author{}

\address{8514 Villa La Jolla Drive \# 114, La Jolla, CA, 92037\medskip}
\email{yiz044@ucsd.edu}

\address{9500 Gilmam Drive \# 0112, La Jolla, CA, 92093 \medskip}
\email{mdressler@ucsd.edu}



%\subjclass[2010]{Primary: 14P10, 90C25; Secondary: 12D05, 52B20}
\keywords{some keywords go here}


\begin{document}
 

\begin{abstract}
Short description
\end{abstract}

\maketitle


\section{Introduction} 
Polynomial with real coefficients is a very powerful tool in terms of expressing problems. 
It has a vast range of applications, in both theory side and engineering side. 
Deciding the nonegativity of a multivariate polynomial, natually, become 
a cenctral prblem for many optimizations and feasibility problems. 
However, it is known that deciding the nonegativity of an arbitrary multivariate 
polynomial is a NP-hard problem when the degree of the polynomial is greater than or
equals to 2. Therefore, we restrict our focus to decide whether the polynomial can be 
expressed in \emph{sum of squares (SOS)} form. 

\begin{definition}
     Sum of Suqares (SOS)

     Let $\mathbb{R}[x]_{n, d}$ denotes the set of polynomials with $n$ real variables with
     degree at most $d$.
     A polynomial $p(x) \in \mathbb{R}[x]_{n, 2d}$, 
     is a \emph{sum of squares} if
     there exists $q_1(x),...,q_n(x) \in \mathbb{R}[x]_{n, d}$ such that
     \begin{equation}
          p(x) = \sum_{i = 1}^{n} q_i ^2 (x)
     \end{equation}
\end{definition}

It is clear that if a polynomial $p(x)$ is a SOS, then it is nonegative,
Thus, SOS is a (proper) subset of the set of nonegative polynomials. 

We are interested in SOS beacuse given a multivariate polynomial, the decision
problem of whether it can be decomposed into SOS is a polynomial time problem, by using
\emph{Semidefinite Programing (SDP)}.


\begin{thm}
     A multivariate polynomial $p(x) \in \mathbb{R}[x]_{n, 2d}$ is a sum of squares
     if and only if there exists $\mathcal{Q} \in \mathcal{S}^{{n+d \choose d}}$ such that
     
     \begin{equation}
          p(x) = [x]_d^T \mathcal{Q} [x]_d \quad \mathcal{Q} \succcurlyeq 0
     \end{equation}

     Where $[x]_d$ denotes the vector of monomials with degree at most $d$.
\end{thm}

\cite{Blekherman:Parrilo:Thomas}

\cite{Laurent:Survey}

As a consequence of the above theorem, whether a multivariate polynomial is SOS can be determined 
by a \emph{Semidefinite Programming}. Notice that, the size of the semidefinite matrix,
${n+d \choose d}$, when fixing $d$, grows in polynomial time with respect to $n$, and when 
fixing $n$, it grows in polynomial time with respect to $d$. Thus, though imposed some 
limitation, we have "redueced" a NP-Problem to a P problem. 

In the above theorem, there is nothing special with monomials other than being a basis of the vector space $\mathbb{R}[x]_{n,2d}$. 
Instead of using $[x]_d$ to proceed the calculation,
we can choose any basis of the vector space of polynomials $\mathbb{R}[x]_{n,d}$. 
For example, we can choose Lagrange basis, Chebychev basis, ... And in the most cases,
the monomial basis is not the right choice due to its instability of monomials bases.

In this paper, we will use python program to analyze the computational effeciency and 
numerical stability of the usage of different bases. In particular, the analysis will
be focusing on the condition number of the linear system generated when solving the 
semidefinite program, that is generated by $p(x) = [x]_d^T \mathcal{Q} [x]_d $. 
We will use the \emph{conditional number} of the matrix in the linear system to identify how stable the
it is under noises that are introduced in practical problems.  
We will further attempt to identify some most effective bases for some particular
type of polynomials, and will try to justify the reasons.  


\section{Preliminaries}
\label{Sec:Preliminaries}

Here background definitions etc will be put. 
YOu can do it in several subsections (like notation, bla, blabla)

\subsection{Notations and Definiations}
\label{Sec:Notations and Definiations}

\begin{definition}
     Let $\mathbb{R}[x]_{n,d}$ denotes the set of real coefficient 
     polynmials with $n$ variables and at most $d$ degree.
\end{definition}

\begin{definition}
     Let $P_{n, 2d}$ denotes the set of nonegative polynomials with 
     $n$ variables and at most $2d$ degree, that is 
     \begin{equation}
          P_{n, 2d} = \{ p \in \mathbb{R}[x]_{n, 2d}: p(x) \geq 0, \forall x \in \mathbb{R}^d \}
     \end{equation}
\end{definition}

\begin{remark}
     There is no reason to consider the set $P_{n, d}$ when $d$ is odd, since if the 
     degree of a polynomial is odd, then it will always be nonegative at some point.
\end{remark}

\begin{definition}
     Let $\Sigma_{n,2d}$ denotes the set of polynomials with $n$ variables and at most
     $d$ degree that are \emph{Sum of Suqares}, that is
     \begin{equation}
          \Sigma_{n, 2d} = \{ p \in \mathbb{R}[x]_{n, 2d}: \exists \text{ } q_1(x), ..., q_k(x) \in \mathbb{R}[x]_{n,d} \text{ } s.t. \text{ }  p(x) = \sum_{i=1}^k q_i^2(x)\}
     \end{equation}     
\end{definition}

\begin{definition}
     Given a matrix $A \in \mathbb{R}^{n \times m}$, the \emph{pesudo-inverse},
     which is also knows as the \emph{Moore-Penrose} inverse of $A$, is the matrix
     $A^+$ satisfying:
     \begin{itemize}
          \item $A A^+ A = A$
          \item $A^+ A A^+ = A^+$
          \item $(A A^+)^T = A A^+$
          \item $(A^+ A)^T = A A^+$
        \end{itemize}
     Every matrix has its pesudo-inverse, and when $A \in \mathbb{R}^{n \times m}$ is \emph{full rank}, 
     that is $rank(A) = min\{n, m\}$, $A$ can be expressed in simple algebric form.
     
     In particular, when $A$ has linearly independent columns, $A^+$ can be computed as
     \begin{equation}
          A^+ = (A^T A)^{-1} A^T
     \end{equation}
     In this case, the pesudo-inverse is called the \emph{left inverse} since $A^+ A = I$.

     And when $A$ has linearly independent rows, $A^+$ can be be computed as
     \begin{equation}
          A^+ = A^T (A A^T)^{-1}
     \end{equation}
     In this case, the pesudo-inverse is called the \emph{right inverse} since $A A^+ = I$. 
\end{definition}

\begin{definition}
     Given a matrix $A \in \mathbb{R}^{n \times m}$, the conditional number of $A$, $\kappa(A)$ is defined as
     \begin{equation}
          \kappa(A) = ||A|| \cdot ||A^+||
     \end{equation}
     for any norm imposed on $A$, for instance \emph{Frobenius norm}.
\end{definition}

\subsection{Solving Semidefinite Program}
\label{Sec:Solving Semidefinite Program}


\section{Numerical Results}


\begin{prop}

\end{prop}

\begin{proof}

\end{proof}

maybe a theorem


\begin{thm}

\end{thm}

or an example...
\begin{example}

\end{example}

pictures are always a good idea...
%\begin{figure}

%\end{figure}


\section{Maybe Some Proofs}


\section{Resume, Outlook, or/and Open Problems}
\label{Sec:Outlook}


what did you do, what questions are still open, natural next steps etc. 

%\section*{Acknowledgements}
%We thank the anonymous referees for their helpful comments.


\bibliographystyle{amsalpha}
\bibliography{main}

\end{document}
